#!/usr/bin/env python3
"""
Dependency Graph Visualization Generator
Creates ASCII art and structured representation of StyleStack dependencies
"""

import json
from collections import defaultdict, deque

def load_analysis():
    """Load the dependency analysis data"""
    with open('/Users/ynse/projects/StyleStack/STYLESTACK_DEPENDENCY_ANALYSIS.json', 'r') as f:
        return json.load(f)

def create_ascii_dependency_tree(data):
    """Create an ASCII representation of the dependency tree"""
    dep_graph = data['raw_dependency_graph']
    reverse_deps = data['raw_reverse_dependencies']
    
    # Focus on key modules
    key_modules = [
        'core.types', 'json_patch_parser', 'ooxml_processor', 'variable_resolver',
        'theme_resolver', 'variable_substitution', 'token_integration_layer',
        'multi_format_ooxml_handler', 'transaction_pipeline', 'template_analyzer'
    ]
    
    lines = []
    lines.append("StyleStack Core Module Dependency Tree")
    lines.append("=" * 50)
    lines.append("")
    
    # Foundation layer
    lines.append("ðŸ“ FOUNDATION LAYER (No Internal Dependencies)")
    foundation_modules = ['core.types', 'json_patch_parser', 'emu_types', 'xml_utils']
    for module in foundation_modules:
        dependents = reverse_deps.get(module, [])
        lines.append(f"â”œâ”€â”€ {module}")
        if dependents:
            lines.append(f"â”‚   â””â”€â”€ Used by: {len(dependents)} modules")
    lines.append("")
    
    # Core services
    lines.append("ðŸ”§ CORE SERVICES")  
    core_services = ['ooxml_processor', 'variable_resolver', 'theme_resolver']
    for module in core_services:
        deps = dep_graph.get(module, [])
        dependents = reverse_deps.get(module, [])
        lines.append(f"â”œâ”€â”€ {module}")
        if deps:
            lines.append(f"â”‚   â”œâ”€â”€ Depends on: {', '.join(deps[:3])}{'...' if len(deps) > 3 else ''}")
        if dependents:
            lines.append(f"â”‚   â””â”€â”€ Used by: {len(dependents)} modules")
    lines.append("")
    
    # Application layer
    lines.append("ðŸš€ APPLICATION LAYER")
    app_modules = ['variable_substitution', 'token_integration_layer', 'template_analyzer']
    for module in app_modules:
        deps = dep_graph.get(module, [])
        lines.append(f"â”œâ”€â”€ {module}")
        if deps:
            lines.append(f"â”‚   â””â”€â”€ Integrates: {', '.join(deps[:4])}{'...' if len(deps) > 4 else ''}")
    lines.append("")
    
    return "\n".join(lines)

def create_module_relationship_map(data):
    """Create a detailed relationship map for key modules"""
    dep_graph = data['raw_dependency_graph']
    reverse_deps = data['raw_reverse_dependencies']
    
    lines = []
    lines.append("Detailed Module Relationship Map")
    lines.append("=" * 40)
    lines.append("")
    
    # Key modules with their full relationship network
    key_modules = data['key_module_profiles']
    
    for module, profile in key_modules.items():
        lines.append(f"## {module}")
        lines.append(f"**Role:** {profile['role']}")
        lines.append(f"**Criticality Score:** {profile['criticality_score']} (modules depend on this)")
        lines.append(f"**Complexity Score:** {profile['complexity_score']} (dependencies this module has)")
        lines.append("")
        
        if profile['dependencies']:
            lines.append("**Dependencies (imports from):**")
            for dep in profile['dependencies']:
                lines.append(f"  â€¢ {dep}")
            lines.append("")
        
        if profile['dependents']:
            lines.append("**Dependents (imported by):**")  
            for dependent in profile['dependents']:
                lines.append(f"  â€¢ {dependent}")
        
        lines.append("")
        lines.append("---")
        lines.append("")
    
    return "\n".join(lines)

def create_import_patterns_analysis(data):
    """Analyze common import patterns in the codebase"""
    detailed_imports = data['detailed_imports']
    
    lines = []
    lines.append("Import Pattern Analysis")
    lines.append("=" * 30)
    lines.append("")
    
    # Analyze import patterns
    internal_import_patterns = defaultdict(int)
    external_import_patterns = defaultdict(int)
    
    for file_path, imports in detailed_imports.items():
        module_name = file_path.split('/')[-1].replace('.py', '')
        
        internal_count = len(imports['internal'])
        external_count = len(imports['external'])
        
        if internal_count == 0:
            internal_import_patterns['foundation_module'] += 1
        elif internal_count <= 2:
            internal_import_patterns['simple_module'] += 1  
        elif internal_count <= 5:
            internal_import_patterns['complex_module'] += 1
        else:
            internal_import_patterns['integration_module'] += 1
    
    lines.append("**Module Complexity Distribution:**")
    lines.append(f"  â€¢ Foundation modules (0 internal deps): {internal_import_patterns['foundation_module']}")
    lines.append(f"  â€¢ Simple modules (1-2 internal deps): {internal_import_patterns['simple_module']}")  
    lines.append(f"  â€¢ Complex modules (3-5 internal deps): {internal_import_patterns['complex_module']}")
    lines.append(f"  â€¢ Integration modules (6+ internal deps): {internal_import_patterns['integration_module']}")
    lines.append("")
    
    # Most common import combinations
    lines.append("**Most Common Internal Import Patterns:**")
    common_combinations = defaultdict(int)
    
    for file_path, imports in detailed_imports.items():
        for imp in imports['internal']:
            # Extract module name from import string
            if '(' in imp:
                module = imp.split('(')[0].strip()
            else:
                module = imp
            
            # Clean up module name
            if module.startswith('tools.'):
                module = module[6:]
            common_combinations[module] += 1
    
    top_internal_imports = sorted(common_combinations.items(), key=lambda x: x[1], reverse=True)[:8]
    for module, count in top_internal_imports:
        lines.append(f"  â€¢ {module}: imported {count} times")
    
    return "\n".join(lines)

def main():
    """Generate comprehensive dependency visualization"""
    data = load_analysis()
    
    # Generate different views
    ascii_tree = create_ascii_dependency_tree(data)
    relationship_map = create_module_relationship_map(data) 
    import_patterns = create_import_patterns_analysis(data)
    
    # Combine all visualizations
    full_report = f"""
{ascii_tree}

{relationship_map}

{import_patterns}

## External Dependencies Summary

**Top Standard Library Usage:**
â€¢ typing: 72 modules (type annotations)
â€¢ pathlib: 56 modules (modern path handling)  
â€¢ dataclasses: 38 modules (data structures)
â€¢ json: 36 modules (configuration/serialization)
â€¢ time: 27 modules (performance timing)
â€¢ logging: 27 modules (diagnostic logging)

**Specialized Libraries:**
â€¢ xml.etree.ElementTree: 14 modules (XML processing)
â€¢ lxml: 12 modules (advanced XPath operations)
â€¢ zipfile: 16 modules (OOXML file handling) 
â€¢ threading: 16 modules (concurrency)
â€¢ concurrent.futures: 11 modules (async processing)

**Office Integration:**
â€¢ PIL: 5 modules (image processing)
â€¢ docx, openpyxl, pptx: 1 each (Office document libraries)

## Architecture Health Report

âœ… **Strengths:**
- Zero circular dependencies
- Clean layered architecture  
- Stable foundation (core.types)
- Minimal external dependencies
- Consistent import patterns

âš ï¸ **Areas for Optimization:**
- High coupling on core.types (11 dependents)  
- Complex integration modules (7+ dependencies)
- PowerPoint-specific complexity

ðŸ“ˆ **Maintainability Score: A-**
Excellent architectural foundation with room for optimization in complex integration layers.
"""
    
    # Save visualization report
    with open('/Users/ynse/projects/StyleStack/DEPENDENCY_VISUALIZATION.md', 'w') as f:
        f.write(full_report)
    
    print("Dependency Graph Visualizations Generated")
    print("=" * 45)
    print("ASCII dependency tree created")
    print("Module relationship map generated")  
    print("Import pattern analysis completed")
    print()
    print("Files created:")
    print("  â€¢ DEPENDENCY_MAP_SPECIFICATION.md - Technical specification")
    print("  â€¢ DEPENDENCY_VISUALIZATION.md - Visual representations")
    print("  â€¢ STYLESTACK_DEPENDENCY_ANALYSIS.json - Raw analysis data")

if __name__ == "__main__":
    main()